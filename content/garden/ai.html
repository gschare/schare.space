<title>
On the Uses of AI in Creative Work
</title>
<!-- provenance: local 24.07.25-20.10.md -> garden/ai.html -->
<h1 id="on-the-uses-of-ai-in-creative-work">On the Uses of AI in
Creative Work</h1>
<span id="date"><em>Jul 25, 2024</em></span>
<p>
</p>
<p><span class="warning"><strong>Note: this is a draft that I am
actively working on.</strong></span></p>
<p>Last night I attended a demo night at <a
href="https://www.southparkcommons.com/">South Park Commons</a> where
some folks working on AI and <a
href="https://malleable.systems/">malleable software</a> gave demos of
their recent creations.</p>
<p>The prevailing sentiment: AI (specifically LLMs) enable malleability
<strong><em>right now</em></strong>.</p>
<h2 id="computers-did-it-backwards">Computers Did It Backwards</h2>
<p><a href="https://thesephist.com/">Linus Lee</a> gave an excellent
talk proposing the synthesis of thought using LLM interfaces. He
remarked on the history of arts becoming sciences. Consider music. We
started by creating sounds using materials from nature, and through
trial and error we learned how to create these sounds consistently and
how to manufacture instruments to deliver a desired sound. We had
sophisticated notions of timbre, pitch, and timing. Then we began to
understand the physics of sound, created a mathematical model of sound
waves, and used this model to create synthesizers which could generate
any sound electronically. Thus art became science and then engineering,
and craft became industrialized. The same process occurred with visual
art and color. What about computing?</p>
<p>Computers began as rational instruments for mathematical calculation.
It took a century of work before we could imagine creative uses for
them, and another half-century before artificial intelligence progressed
to the point of enabling general-purpose fuzzy computation using LLMs.
Now we must follow the trend and discover a mathematical model of LLMs
in order to use them effectively as a tool for thought. <a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<!--## Explainability
_Explainability_, a term thrown around in AI research that I don't really
understand. Let me abuse it here to talk about insight into the process.-->
<h2 id="the-two-uses-of-ai">The Two Uses of AI</h2>
<p>When we leverage LLMs in the creative process (be it programming,
writing, or even non-text mediums like design, visual art), a familiar
tension arises: the use of AI enables us and augments us, but diminishes
our agency and threatens to reduce us from an active to a passive role.
This is familiar because every technological advancement in art (made
possible by the aforementioned mathematical models) goes this way. For
example: from painting to photography, then digital photography, then AI
editing, then AI image generation…</p>
<p>This tension can be resolved by piecing apart the two ways one wants
to use AI in creative work: as spectacle and as assistant.</p>
<p>TODO</p>
<h3 id="ai-as-spectacle">AI as Spectacle</h3>
<p>For inspiration, and end-users to delegate the creative process to an
oracle</p>
<p>Also occasionally useful to the skilled artist</p>
<p>TODO</p>
<p>Qualities:</p>
<ul>
<li>defy the user’s expectations</li>
<li>expand the user’s abilities</li>
<li>surprise the user</li>
<li>do things the user can’t</li>
<li>produce a finished product</li>
<li>general-purpose, which means it can help with uses the designers of
the software did not intend
<ul>
<li>e.g. Kuwaiti dentist using websim</li>
</ul></li>
</ul>
<h3 id="ai-as-assistant">AI as Assistant</h3>
<p>Automate the boring stuff. For an experienced craftsman to focus on
their overall design while speeding up stuff they know how to do, but
isn’t that interesting or new or deep, while still having access to the
manual method if they need it.</p>
<p>TODO</p>
<p>Qualities:</p>
<ul>
<li>augment the user’s existing abilities</li>
<li>defer to the user in all decisions</li>
<li>be explainable, interpretable, changeable</li>
<li>follow a process, not just random inspiration</li>
<li>only do things the user can already do, but faster</li>
<li>operate on a small, structured piece of a whole
<ul>
<li>see Geoffrey’s structured AI diffs in <a
href="https://www.inkandswitch.com/patchwork/notebook/">Patchwork</a></li>
</ul></li>
<li>specialized, situated, opinionated</li>
</ul>
<h2 id="improvements-to-ai">Improvements to AI</h2>
<p>TODO</p>
<ul>
<li>what AI will be able to do soon:
<ul>
<li>LLMs will become:
<ul>
<li>faster</li>
<li>cheaper</li>
<li>better at humor, creativity</li>
<li>better at scientific reasoning</li>
<li>highly personalized</li>
<li>highly situated</li>
<li>multimodal in both input and output</li>
<li>enabled agents (can perform operations on their own, subject to user
approval)</li>
</ul></li>
<li>what they won’t be able to do? be robust, reliable, consistent.
that’s not their purview</li>
</ul></li>
</ul>
<h2 id="ai-maximalism">AI Maximalism</h2>
<p>TODO</p>
<ul>
<li>cost will go down but still costly</li>
<li>vs AI minimalism</li>
<li>AI companies vs companies that happen to use AI as a tool
<ul>
<li>former is usually AI as spectacle, latter is usually AI as
assistant</li>
</ul></li>
</ul>
<h2 id="explainable-ai">Explainable AI</h2>
<p>TODO</p>
<ul>
<li>Concepts/Components</li>
<li>LLMs good at javascript webapps because they’re trained on a huge
sample of code for that…
<ul>
<li>admit that this is the underlying structure (the “IR” of LLMs) and
exploit it</li>
</ul></li>
</ul>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>There is a mathematical model for how
LLMs <em>work</em>, but not for what they <em>do</em>. To make a rough
analogy: suppose we had 3D printers capable of creating perfect wooden
instruments, but absolutely no idea how sound waves work. We would
totally empowered to make the best instruments, but totally blind to
what makes an instrument make the sounds we want. This is what prompting
is like.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
