<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta charset="utf-8"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@ggschare"><meta name="twitter:title" content="schare.space: a website"><meta name="twitter:description" content="Lasciate ogne speranza, voi ch'intrate."><meta name="twitter:image:src" content="https://schare.space/assets/img/nessie.jpg"><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" type="text/css" href="/css/default.css"><link rel="stylesheet" type="text/css" href="/css/article.css"><link rel="stylesheet" type="text/css" href="/css/garden.css"><link href="https://fonts.googleapis.com" rel="preconnect"><link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="crossorigin"><link href="https://fonts.googleapis.com/css?family=Lora:ital,wght@0,400..700;1,400..700" rel="stylesheet" type="text/css"><link href="/css/pandoc-highlighting.css" rel="stylesheet" type="text/css"></head><body><header>
    <div>
        <div style="display: inline-block;">
            <nav>
                <a id="nav-home" href="/">Home</a>
                &centerdot;
                <a id="nav-tidings" href="/tidings/">Tidings</a>
                &centerdot;
                <a id="nav-garden" href="/garden/">Garden</a>
                &centerdot;
                <a id="nav-now" href="/now.html">Now</a>
                &centerdot;
                <div style="display: inline-block;">
                    <button class="fancybutton" title="Dark mode" onclick="toggleDarkMode()" type="button" id="dark-mode-button" style="border: none;"><div style="filter: hue-rotate(180deg) brightness(105%) grayscale(90%);">üåï</div></button>
                    <script>
        // Start light
        function goDark() {
            document.body.classList.add('dark-mode');
            document.getElementById('dark-mode-button').innerHTML = "‚òÄÔ∏è";
            document.getElementById('dark-mode-button').title = "Light mode";
            localStorage.setItem('dark-mode', 'enabled');
        }

        function goLight() {
            document.body.classList.remove('dark-mode');
            document.getElementById('dark-mode-button').innerHTML = '<div style="filter: hue-rotate(180deg) brightness(105%) grayscale(90%);">üåï</div>';
            document.getElementById('dark-mode-button').title = "Dark mode";
            localStorage.setItem('dark-mode', null);
        }

        function toggleDarkMode() {
            var containerClasses = document.body.classList;
            if (containerClasses.contains('dark-mode')) {
                goLight();
            } else {
                goDark();
            }
        }

        if (localStorage.getItem('dark-mode') === 'enabled') {
            goDark();
        }
                    </script>
                </div>
            </nav>
        </div>
    </div>
</header>
<main><div id="modal" class="modal"><div id="modal-content" class="modal-content"><img id="modal-image" class="modal-image" src=""></div></div><script src="/js/modal.js"></script><article class="article"><!--  provenance: local 24.09.04-01.24.md -> garden/chiang.html  -->
<h1 id="ted-chiang-is-wrong-about-ai-and-also-he-doesnt-seem-to-know-how-art-is-made">Ted
Chiang Is Wrong About AI, And Also He Doesn‚Äôt Seem To Know How Art Is
Made</h1>
<span id="date">Sep 3, 2024</span>
<title>
Ted Chiang Is Wrong About AI, And Also He Doesn‚Äôt Seem To Know How Art
Is Made
</title>
<style>
p {
   text-justify: inter-word;
   text-align: justify;
}

hr {
   all: revert;
   border: none;
   color: var(--fg-light);
   text-align: center;
}

hr::before {
  content: "* * *";
}
</style>
<p><span class="warning"><strong>Note: what follows is a <em>rough
draft</em> containing some ideas I had when reading Chiang‚Äôs
essay.</strong></span></p>
<p>Ted Chiang, a wonderful sci-fi writer, wrote an <a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art">article
in the New Yorker</a> titled ‚ÄúWhy AI Isn‚Äôt Going to Make Art,‚Äù in which
he betrays his lack of imagination about the future of human-AI
interaction and a shallow understanding of the relationship between
artistic output and artistic process.</p>
<p>Chiang wonders:</p>
<blockquote>
<p>Right now, the fiction generated by large language models like
ChatGPT is terrible, but one can imagine that such programs might
improve in the future. How good could they get?</p>
</blockquote>
<p>The answer: very, very good, and integrated into our workflow in ways
we cannot yet imagine. For example, Chiang seems to assume that the way
we use AI will remain static.</p>
<blockquote>
<p>The selling point of generative A.I. is that these programs generate
vastly more than you put into them, and that is precisely what prevents
them from being effective tools for artists.</p>
</blockquote>
<p>This general mode of small prompt to large output is indeed the norm‚Ä¶
for the first large companies who create the models themselves, and
currently have a monopoly on their usage. As AI becomes ubiquitous in
software, we will see <a href="https://maggieappleton.com/lm-sketchbook">interfaces</a> that <a href="https://www.inkandswitch.com/patchwork/notebook/">integrate AI
more closely</a> with the existing tools. To speak broadly: we are
presently reacting to advances in <em>generative</em> AI, which has its
uses as I will defend later. But soon, as designers hone in on the more
effective ways to leverage AI, we will be confronted with a more subtle
and sophisticated form: <em>assistive</em> AI. And already we see, as
Chiang mentions (albeit only in the extreme case), AI being used to
generate an output via iteration, which necessarily requires the human
to take an active role collaborating with the artificial agent.</p>
<p>It‚Äôs easy to see why his perspective is limited. He tells us himself,
by analogy to the invention of photography:</p>
<blockquote>
<p>When photography was first developed, I suspect it didn‚Äôt seem like
an artistic medium because it wasn‚Äôt apparent that there were a lot of
choices to be made; you just set up the camera and start the
exposure.</p>
</blockquote>
<p>He explains it took time for photography to be accepted as an art
form of its own, yet he fallaciously expects AI as a tool for art-making
to demonstrate immediate depth. The first cameras were crude, simple
machines. Chiang looks at DALL-E and sees early photographic techniques
like a daguerrotype. This analogy may be accurate: daguerrotypes were
limited in what they could produce (and how they could be manipulated
during or after the photograph is taken), difficult or impossible to
reproduce results exactly, and a small change in chemical process could
alter the effect completely‚Äîreflecting the differences between versions
of DALL-E. So to extend the analogy, AI <em>in general</em> is not one
particular camera, but the invention of photosensitive film. Consider
the myriad of particular devices and cameras that leveraged so many
different kinds of film‚Ä¶ and the revolution of digital photography
rooted in the invention of electronic photosensors. We just passed the
‚Äúcamera obscura‚Äù stage of AI. We have not yet found the ‚Äútwin-lens
reflex camera‚Äù of AI, let alone the Leica.</p>
<hr>
<p>Chiang admits that fine-grained control over images or text produced
in collaboration with AI would assuage his unease over calling the
result ‚Äúart.‚Äù He goes further and explains that it is careful,
exhausting effort itself that qualifies creative output as art. He is
subtly wrong about this, but makes some keen observations:</p>
<blockquote>
<p>The companies promoting generative-A.I. programs claim that they will
unleash creativity. In essence, they are saying that art can be all
inspiration and no perspiration‚Äîbut these things cannot be easily
separated.</p>
</blockquote>
<p>He is so very close to the essence of art, here, but he does not
interrogate <em>why</em> perspiration makes the art. Before we proceed,
I must clarify what kind of art we are talking about.</p>
<p>It would be unfair to accuse Chiang of being ‚Äúanti-AI‚Äù being applied
to generating images or text‚Äîhe gives the example of using AI to
generate replies to boring business emails (as opposed to personal
emails, which we imagine demand a personal touch and a detectable sense
of effort). AI is doing a funny thing here: inundated as we are with
useless, low-effort, often auto-generated emails, AI allows the humble
recipient to respond in kind, with low-effort automation. In that sense,
it liberates us from drowning in bureaucracy. That being said, Chiang
rightfully points out the absurdity of this situation:</p>
<blockquote>
<p>We are entering an era where someone might use a large language model
to generate a document out of a bulleted list, and send it to a person
who will use a large language model to condense that document into a
bulleted list. Can anyone seriously argue that this is an
improvement?</p>
</blockquote>
<p>I maintain that it is an improvement: by accelerating the injustice
of meaningless work to its logical absurdity, we put a spotlight on it.
Hopefully then we can eliminate it entirely.</p>
<p>Chiang apparently fears, as many reasonably do, that we will throw
the baby out with the bathwater and lose that personal touch, that AI
‚Äúreduces the amount of intention in the world.‚Äù This fear is grounded
because right now we only have one kind of AI tool: generative AI, which
robs us of the experience of creating in the medium. He cites that awful
Google Gemini commercial from the Olympics. But is a letter to your hero
art? What about concept art‚Äîcan we, in good conscience, use AI for that?
What about work that traditionally requires tedious attention to detail,
but which may not be called ‚Äúart,‚Äù like the graphic design of road signs
or logos‚Äîcan we use AI for those?</p>
<p>I think these are subjects worth discussing, but they‚Äôre not the
point of the essay. The point, rather, is about human effort, intention,
and expertise. Chiang is talking about Art, with a capital A,
<em>defined</em> as that which is ‚Äúthe result of effort expended by [a]
person.‚Äù He furthermore draws a distinction between artists and
non-artists; the line is that non-artists want to produce art in a
particular medium without actually working in it, while artists revel in
the medium. Artists, he claims, are drawn to the medium and wish to take
full advantage of it. The implication is that art is only good when (1)
it took effort and (2) it takes (or endeavors to take) full advantage of
the medium.</p>
<p>Neither of these are necessary for art to be art. Not all art needs
to take full advantage of the medium. We all know this from experience:
a book or film can be conservative, uncreative, or even amateurish in
its techniques, but still arrest us and emotionally affect us with its
story, characters, how we relate to it. And likewise art can be
derivative in its narrative but totally creative and inspirational in
its craft. And further! There is art that entertains without innovating
in either of the aforementioned respects. There is art (broadly
construed) with functional intent, such as signage, public notices, or
translation and accessible captioning. There is art with a message that
shines through shoddy use of the medium‚Äîas much we may cringe at it or
find it ineffective, the message is received‚Ä¶ and AI lowers the barrier
to creating these sorts of things.</p>
<!--  i'm getting a bit lost in the sauce here. these last few paragraphs, and
the next few, are deep in some analytical drudgery without a clear point until
much later, and it would be great to break it up with examples or go back to
being in conversation with Chiang via quotes. I'm not sure.  -->
<p>And what of effort? Effort <em>seems</em> necessary because in all
hitherto history we did not have a ubiquitously available technology for
generating art from a goal-oriented prompt (except by hiring a
professional artist, which is why the Catholic Church and Venetian and
Dutch fur traders are more or less directly responsible for the
Renaissance). Now, perspiration and inspiration are indeed separated,
but we find perspiration still suspiciously present everywhere we find
quality. And this will continue to be the case even as AI models
improve. Why?</p>
<p>Let us be crude and suppose that there are four kinds of art each
with their own goal:</p>
<ol type="1">
<li>Art that advances the medium.</li>
<li>Art that entertains.</li>
<li>Art that serves a practical function.</li>
<li>Art that sends a message.</li>
</ol>
<p>Only the first, advancing the medium, really requires taking full
advantage of the medium. It is novel in its form such that a stochastic
parrot cannot be expected to synthesize it (yet). While the other three
may leverage the medium to support their goals, if their intention is
clear and known, the artist may‚Äîone day‚Äîbe able to tell an artificial
agent exactly what you want to say and receive the desired output
without any effort at all.</p>
<p>But there‚Äôs the rub. What if you don‚Äôt know what you want? Most of
the time this is the case. The painstaking, even tedious process of
generating art which Chiang identifies as integral to quality output is
just the manifestation of the process of <em>figuring out what you are
trying to do</em>. Those ten thousand choices involved in writing a
short story are not independent of each other; they cause harmony and
friction and each choice is informed by every previous one, such that
the artist is guided by an evolving fragment of the final output. This
is exactly how an LLM works with its context window. Furthermore, the
experienced artist and the trained model draw on innumerable examples
from the past, making the tedious work of <em>learning</em> the medium
necessary to know how to refine an incomplete work. That‚Äôs why Chiang
regards ten thousand iterations as art, but one prompt with one output
as an indignity to the human project of art-making. When the AI
generates the whole output for you, you are a passive delegator in this
process, unable to be involved in subtly shifting direction in response
to partial feedback. But if you have the machine generate sketches and
refine them in conversation, pointing out details and perhaps employing
other software to make manual edits, you have a much better shot at
succeeding in the critical exploratory process. That ‚Äúbrilliant idea‚Äù of
the non-artist for which they want 50% of the profits is probably just
the seed of something that will‚Äîmust‚Äîchange completely when it comes
into contact with the real world, the refinement process guided by the
trained eye of an artist‚Äîor a machine with a whole bunch of
examples.</p>
<p>With effort as a proxy for the process of finding your true goal
given a vague idea, engagement with the medium is a proxy for knowing,
at each concrete step, where to go next. As Chiang correctly points out,
to make effective art you must be an expert in the medium, and actually
work in it, so that you may leverage it to support your goal as you
discover it. This is the insufficiency with present AI interfaces (and
most art software): they do not support <em><a href="https://worrydream.com/">direct manipulation</a></em>. Just as we
invented styluses for digital painting, we will invent better ways to
integrate AI with the medium, such that detail work can be more direct
when called for. Certainly the chatbot is not the end of art history. If
you have ideas about this, shoot me an email at <a href="mailto:schare@mit.edu">schare@mit.edu</a>; I‚Äôd love to
discuss.</p>
<p>My provocative counter-claim is that you can use AI <em>as much as
you want</em> in generating these outputs, and it will still be art. It
may be very shitty art, but it is art. Instead of arguing what is and
isn‚Äôt art, let us argue about how to make <em>good</em> art‚Äîgood in the
sense that it accomplishes its goal, whichever of the four categories
you fall into. If you want to employ AI in this process, you are
unlikely to get a very good result with current tools because chatbots
(without extensive system prompting) are not yet great collaborators in
iterating ideas. But where I <em>have</em> heard anecdotes of success in
using AI towards creative work, it is overwhelming because the artist
used the chatbot as a surface with which to bounce ideas, check for
biases and omissions, and discuss ideas, not to generate large portions
of the final output, if at all. AI is here and not going away. Instead
of wishfully claiming it will never have a role in the production of
art, let‚Äôs talk about how to make it better at helping us do what we
do.</p>
<hr>
<p>The implications for education are obvious. Students must learn the
concrete skill of using the most state-of-the-art AI interfaces just as
we teach the state-of-the-art techniques in mathematics, composition,
science, etc. And just as we teach the ‚Äúsoft skill‚Äù of learning how to
critique and edit one‚Äôs own work and that of others‚Äîthis necessary
process of recognizing shortcomings and refining until the goal is
achieved‚Äîwe must continue to do so in the context of a world where AI
can be a useful tool. I spoke to a former teacher of mine about this. He
teaches both mathematics and the humanities. In mathematics, he allows
students to use AI to check their work on assignments, just as they
likely already did with tools like Wolfram Alpha or using online answer
sets. He warns them that AI models are imperfect and may produce
incorrect results that would only confuse them more; this, too, only
differs from the pre-2022 status quo in that ChatGPT is much more
accessible than Chegg or similar. He also allows his math students to
use the AI as a sort of tutor for understanding concepts‚Äîalbeit with the
same warning. In the humanities, has adopted a policy of having his
students start working on their essays in the last few minutes of class,
take a picture, and hand him the partial work before going home and
finishing it with as much use of AI as they like. Thus he ensures his
students at least began with an attempt to generate original ideas, and
it allows him to look for elaborations of those initial ideas in the
students‚Äô final output. If they abandoned their initial ideas in favor
of having ChatGPT generate the entire assignment, he would notice. This
model is ideal because it acknowledges the existence and ubiquity of AI
tools, encourages their use where most appropriate and helpful (while
teaching their shortcomings) but does not require it, and still
emphasizes and requires the development of fundamental critical-thinking
skills.</p>
<hr>
<p>In his article, Chiang edges frighteningly close to gatekeeping art
from the masses, reserving it only for those with a formal background,
with time to spend inordinate effort on generating artistic output, and
with ‚Äútrue appreciation‚Äù for artistic media according to some arbitrary
criteria. AI is not his enemy here; rather it is the proliferation of
easily-created low-quality (or even malicious) content. Unfortunately,
this is the double-edged sword of technology, and it is by no means
unique to AI. By any metric, the last two decades have made it ever more
easy to generate art and have it seen by millions of eyes no matter the
quality. 99% of everything is shit, and will always be shit; technology
just increases the amount of shit in absolute terms. Chiang fails to
plainly identify his real fear: that AI makes it easier to create crappy
art, but does not provide experts with any augmentation to their
process‚Äîraising the floor without raising the ceiling. So far this is
true, but it can change, so long as artists see the potential in this
new technology and get involved in the development of better interfaces
designed specifically to support meaningful human expression.</p>
<!--  I'm ignoring the latter half of Chiang's article, which deals with copyright. I,
uh, have complicated feelings about this topic, but I honestly do not have
strong enough convictions yet to respond to his points either in agreement or
disagreement. But to say _something_: I think the arguments we leverage against
AI "stealing" art hint at the insufficiency of 20th century notions of copyright
in today's digital world. We need to move beyond intellectual property (the
Marxist apologist in me says we need to move beyond property altogether...) and
AI is maybe a catalyst technology here. I'm not sure if I should include this
point in my response.  -->
<!--  also, do I have to respond to his philosophical points about what makes
intelligence, intention, language, etc? No. A better question: should I make
clear that I'm *not* responding to those aspects of this essay? My response is
along one or two vectors that I make clear upfront in the first paragraph.
Perhaps I should thread that narrow intention throughout my response so my scope
is clear.  -->
</article></main></body></html>